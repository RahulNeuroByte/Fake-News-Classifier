# ğŸ“° Fake News Classification Project

A comprehensive machine learning project for detecting fake news using multiple algorithms and a user-friendly Streamlit web application.

## ğŸš€ Live Demo

[Click here to view the deployed Fake News Classifier App](https://fake-news-classifier-rahulneurobyte.streamlit.app/)

## ğŸ¯ Project Overview

This project implements a complete fake news classification system with the following features:

- **Multiple ML Models**: Naive Bayes, Logistic Regression, KNN, SVM, Random Forest
- **Text Vectorization**: Both Count Vectorizer and TF-IDF Vectorizer
- **Hyperparameter Tuning**: Automated optimization for best performance
- **Interactive Web App**: Streamlit-based interface for real-time predictions
- **Batch Processing**: Support for CSV file uploads and bulk predictions
- **Comprehensive Evaluation**: Detailed performance metrics and visualizations
- **Easy Deployment**: Ready for local and cloud deployment

## 1 ğŸ“ Project Structure

```
Fake_News_Classifier/
â”‚
â”œâ”€â”€ data/                          # Dataset storage
â”‚   â””â”€â”€ dataset.csv               # Main dataset (place your dataset here)
â”‚
â”œâ”€â”€ models/                       # Trained models and vectorizers
â”‚   â”œâ”€â”€ *.pkl                    # Saved model files
â”‚   â”œâ”€â”€ *_vectorizer.pkl         # Vectorizer files
â”‚   â”œâ”€â”€ best_model.pkl           # Best performing model
â”‚   â””â”€â”€ best_model_info.pkl      # Model metadata
â”‚
â”œâ”€â”€ results/                      # Evaluation results and visualizations
â”‚   â”œâ”€â”€ *.png                    # Confusion matrices and plots
â”‚   â”œâ”€â”€ model_comparison.csv     # Model performance comparison
â”‚   â””â”€â”€ evaluation_report.md     # Detailed evaluation report
â”‚
â”œâ”€â”€ app/                          # Streamlit web application
â”‚   â””â”€â”€ streamlit_app.py         # Main application file
â”‚
â”œâ”€â”€ preprocessing.py              # Text preprocessing utilities
â”œâ”€â”€ model_training.py            # Model training pipeline
â”œâ”€â”€ model_evaluation.py          # Model evaluation utilities
â”œâ”€â”€ model_tuning.py              # Hyperparameter tuning
â”œâ”€â”€ prediction_pipeline.py       # Prediction pipeline
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```



### 2. Data Preparation

1. **Place your dataset** in the `data/` folder as `dataset.csv`
2. **Dataset format**: Your CSV should have:
   - A text column (named 'text', 'news', or 'content')
   - A label column (named 'label', 'target', or 'class')
   - Labels should be binary: 0 for Fake, 1 for Real

### 3. Model Training

This will:
- Preprocess the text data
- Train multiple models with different vectorizers
- Evaluate and save all models
- Generate performance visualizations
- Save the best performing model

### 4. Hyperparameter Tuning
- Tuning various model for high accuracy 

### 5. Launch the Web Application 

# Run the Streamlit app
## Visit this link (https://fake-news-classifier-rahulneurobyte.streamlit.app/)


## ğŸ”§ Configuration and Customization

### File Paths Configuration

All file paths are clearly marked with `# FILE PATH:` comments. Key locations to update if needed:

1. **Dataset location**: Update `data_path` in training scripts
2. **Models directory**: Update `models_dir` in prediction pipeline
3. **Results directory**: Update `results_dir` in evaluation scripts
4. **App imports**: Update `sys.path.append()` in Streamlit app

### Model Configuration

To add new models or modify existing ones:

1. **Edit `model_training.py`**: Add new models to `models_config` dictionary
2. **Edit `model_tuning.py`**: Add parameter grids for new models
3. **Update preprocessing**: Modify `preprocessing.py` for custom text processing

### Vectorizer Configuration

Current vectorizers use:
- `max_features=5000`: Adjust based on dataset size
- `stop_words='english'`: Change for other languages
- Custom preprocessing pipeline in `preprocessing.py`

## ğŸ“Š Features and Capabilities

### Web Application Features

1. **Single Text Prediction**
   - Real-time classification of news articles
   - Confidence scores and probability breakdown
   - Interactive visualizations

1. **Multiple Algorithms**
   - Naive Bayes (MultinomialNB)
   - Logistic Regression
   - K-Nearest Neighbors
   - Support Vector Machine
   - Random Forest

2. **Text Vectorization**
   - Count Vectorizer
   - TF-IDF Vectorizer
   - Automatic comparison and selection

3. **Evaluation Metrics**
   - Accuracy, Precision, Recall, F1-Score
   - Confusion matrices
   - ROC curves and AUC scores
   - Detailed classification reports

## ğŸ“ˆ Performance Optimization

### For Large Datasets

1. **Increase max_features** in vectorizers
2. **Use incremental learning** for very large datasets
3. **Consider feature selection** techniques
4. **Implement data sampling** for faster training

### For Better Accuracy

1. **Run hyperparameter tuning**: `python model_tuning.py`
2. **Experiment with ensemble methods**
3. **Try different preprocessing techniques**
4. **Use domain-specific stop words**

---

**Happy Fake News Detection! ğŸ¯**
















ğŸ”§ Setup Instructions & Usage Guide
1. ğŸ“ Data Preparation
Prepare your dataset before training:

Place your dataset in the data/ directory as dataset.csv

Dataset format must include:

A text column named either text, news, or content

A label column named either label, target, or class

Binary labels:

0 â†’ Fake news

1 â†’ Real news

2. âš™ï¸ Model Training
Running model_training.py will:

Preprocess text data (cleaning, lemmatization, etc.)

Train multiple machine learning models using:

Count Vectorizer

TF-IDF Vectorizer

Evaluate all models

Save trained models and vectorizers

Generate performance visualizations

Automatically save the best-performing model

3. ğŸ¯ Hyperparameter Tuning (Optional)
For improved accuracy:

Run model_tuning.py

Performs GridSearchCV or RandomizedSearchCV

Fine-tunes hyperparameters for each model

4. ğŸš€ Launch the Streamlit Web App
Once training is complete:

bash
Copy
Edit
streamlit run app/app.py
Or visit the live version:

ğŸ‘‰ Live App

âš™ï¸ Configuration & Customization
ğŸ”„ File Paths Configuration
Key configurable file paths (marked as # FILE PATH: in scripts):

Component	File Path to Update
Dataset	data_path in training scripts
Models directory	models_dir in prediction_pipeline.py
Results directory	results_dir in evaluation scripts
App imports	sys.path.append() in app.py

ğŸ§  Model & Preprocessing Customization
Add New Models:

Update models_config in model_training.py

Add New Hyperparameters:

Edit grid in model_tuning.py

Customize Preprocessing:

Modify preprocessing.py for cleaning, stopword filtering, etc.

ğŸ§ª Vectorizer Configuration
Default vectorizers:

CountVectorizer

TfidfVectorizer

Settings:

max_features=5000 â€” adjust for large datasets

stop_words='english' â€” can be customized

Custom preprocessing pipeline via preprocessing.py

ğŸ“Š App Features & Capabilities
ğŸ” Web Application Modes
Single Text Prediction

Real-time classification of a headline/article

Displays:

Predicted label (Fake/Real)

Confidence score

Probability distribution

Visuals (bar chart & gauge)

Batch File Prediction

Upload .csv file

Returns predictions for all rows

Summary stats and download option

Model Performance View

Accuracy comparison of all models

Visualizations (confusion matrices, bar charts)

ğŸ§  Supported ML Models
Logistic Regression

Multinomial Naive Bayes

K-Nearest Neighbors (KNN)

Support Vector Machine (SVM)

Random Forest Classifier

ğŸ“ˆ Evaluation Metrics
Accuracy, Precision, Recall, F1-Score

Confusion Matrices

ROC Curve & AUC Score

Classification Reports

âš¡ Performance Optimization Tips
For Large Datasets
Increase max_features in vectorizers

Use incremental learning algorithms (e.g., partial_fit)

Implement feature selection

Use stratified sampling to balance training

For Higher Accuracy
Run hyperparameter tuning (model_tuning.py)

Use ensemble models (Voting, Stacking)

Improve text cleaning (domain-specific filters)

Include metadata features (e.g., source credibility)

âœ… Conclusion
This Fake News Classifier project is a complete end-to-end system built with real-world practicality in mind. It combines robust machine learning models, clean text processing, and an interactive Streamlit interface â€” making it a great tool for both educational purposes and potential deployment.

By allowing both individual and bulk predictions with live confidence visualization, the system serves as a solid foundation for combating misinformation online.

ğŸ”® Future Enhancements:

Deep learning models (BERT, LSTM)

Real-time news scraping & classification

Multi-language support

Browser extension integration

Happy Classifying! ğŸ“°ğŸš€

